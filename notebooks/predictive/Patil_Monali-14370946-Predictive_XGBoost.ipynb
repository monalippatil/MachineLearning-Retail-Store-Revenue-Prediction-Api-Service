{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Business Understanding\n",
    "\n",
    "•  **Introduction:** The project, involves working with an American retail chain operating across California (CA), Texas (TX), and Wisconsin (WI). This retailer offers a diverse range of products, including hobbies, foods, and household items, across ten stores. The objective is to develop and deploy two distinct machine learning models as APIs to address specific business challenges:\n",
    "\n",
    "1. Predictive Model: A predictive model to forecast sales revenue for specific items in particular stores on given dates.\n",
    "2. Forecasting Model: A time-series-based forecasting model to predict total sales revenue across all stores and items for the next seven days.\n",
    "\n",
    "These models will help optimize inventory, pricing, and decision-making for our retail partner.\n",
    "\n",
    "•  **Dataset:** To develop and evaluate the models, below datasets are provided:\n",
    "\n",
    "        - Training Data\n",
    "        - Evaluation Data\n",
    "        - Calendar\n",
    "        - Events\n",
    "        - Items Price per Week\n",
    "\n",
    "•  **Business Problem:** The primary business problems that the machine learning models aim to address are as follows:\n",
    "\n",
    "1. Sales Prediction: The retailer needs to accurately predict the sales revenue for individual items in specific stores for any given date.\n",
    "\n",
    "2. Sales Forecasting: The retailer seeks to forecast total sales revenue across all stores and items for the next seven days.\n",
    "\n",
    "This information is crucial for inventory management, pricing strategies, and overall business planning. Our machine learning models aim to address these business challenges by providing precise predictions and forecasts.\n",
    "\n",
    "The following activitives are performed for this Regression learning task.\n",
    "\n",
    "• Business Understanding\n",
    "\n",
    "• Data Understanding\n",
    "\n",
    "        1] Loading Data\n",
    "        2] Exploring Data\n",
    "        3] Combining the training and other datasets\n",
    "\n",
    "• Data Preparation\n",
    "\n",
    "        4] Feature Engineering\n",
    "        5] Features Selection\n",
    "        6] Splitting Data into Different Sets\n",
    "\n",
    "• Modeling\n",
    "\n",
    "        7] Assessing Baseline Performance\n",
    "        8] Sales Prediction Model: XGBoost Algorithm\n",
    "        9] Sales Forecasting Model: Prophet Algorithm\n",
    "\n",
    "• Model Evaluation\n",
    "\n",
    "        10] Analysing Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importing SKLearn libraries for building a Predictive ML Model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# Importing dump library from joblib\n",
    "from joblib import dump\n",
    "\n",
    "# Importing formatting and other required libraries\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Including the project root directory\n",
    "sys.path.append('/Users/monalipatil/Monali/MDSI-Semester1/Advanced Machine Learning Application/Assignment2/adv_mla_assignment2')\n",
    "\n",
    "# Importing class and functions defined to build predictive machine learning model\n",
    "from src.models.null import NullAccuracy\n",
    "from src.data.sets import features_scaling, ordinal_transform, save_datasets\n",
    "from src.models.performance import evaluating_mas_score, evaluating_rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignoring warnings to maintain a clean coding.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Loading the training and validation datasets for developing a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data files path \n",
    "# Note: Change this path to the relevant directory\n",
    "file_url = '/Users/monalipatil/Monali/MDSI-Semester1/Advanced Machine Learning Application/Assignment2/adv_mla_assignment2'\n",
    "\n",
    "# Loading the training and validation dataset into a separate pandas dataframe\n",
    "df_train = pd.read_csv(file_url + '/data/processed/retail_training_dataset.csv')\n",
    "df_validation = pd.read_csv(file_url + '/data/processed/retail_validation_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Generating duplicates of the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the original training and validation datasets\n",
    "df_train_copied = df_train.copy()\n",
    "df_validation_copied = df_validation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>date</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_type</th>\n",
       "      <th>revenue</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17924466</th>\n",
       "      <td>FOODS_3_220</td>\n",
       "      <td>WI_2</td>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17539704</th>\n",
       "      <td>FOODS_2_029</td>\n",
       "      <td>CA_3</td>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11007316</th>\n",
       "      <td>HOBBIES_2_011</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>2012-01-24</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7380796</th>\n",
       "      <td>FOODS_2_390</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>2011-09-27</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2011</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24429827</th>\n",
       "      <td>HOUSEHOLD_2_143</td>\n",
       "      <td>CA_3</td>\n",
       "      <td>2013-04-08</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6.46</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  item_id store_id        date event_name event_type  revenue  \\\n",
       "17924466      FOODS_3_220     WI_2  2012-09-06       None       None     0.00   \n",
       "17539704      FOODS_2_029     CA_3  2012-08-25       None       None     0.00   \n",
       "11007316    HOBBIES_2_011     CA_1  2012-01-24       None       None     1.94   \n",
       "7380796       FOODS_2_390     CA_1  2011-09-27       None       None     0.00   \n",
       "24429827  HOUSEHOLD_2_143     CA_3  2013-04-08       None       None     6.46   \n",
       "\n",
       "          day_of_week  month  year  week_of_year  \n",
       "17924466            3      9  2012            36  \n",
       "17539704            5      8  2012            34  \n",
       "11007316            1      1  2012             4  \n",
       "7380796             1      9  2011            39  \n",
       "24429827            0      4  2013            15  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the random few datapoints of the training dataset\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43814130 entries, 0 to 43814129\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   item_id       object \n",
      " 1   store_id      object \n",
      " 2   date          object \n",
      " 3   event_name    object \n",
      " 4   event_type    object \n",
      " 5   revenue       float64\n",
      " 6   day_of_week   int64  \n",
      " 7   month         int64  \n",
      " 8   year          int64  \n",
      " 9   week_of_year  int64  \n",
      "dtypes: float64(1), int64(4), object(5)\n",
      "memory usage: 3.3+ GB\n"
     ]
    }
   ],
   "source": [
    "# Verifying the feature's datatypes \n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Creating a list of numerical features named 'numerical_features'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to contain the list of features that are of numerical datatype\n",
    "numerical_features = df_train.select_dtypes(include=['int64']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Creating a list of categorical features named 'categorical_features'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to contain the list of features that are of categorical datatype\n",
    "categorical_features = ['item_id', 'store_id', 'event_name', 'event_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Performing features scaling for the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking the function to scale the numerical features values of the training and validation datasets\n",
    "X_train_numerical, scaler = features_scaling(df_train, numerical_features)\n",
    "df_train_numerical, scaler = features_scaling(df_train, numerical_features)\n",
    "\n",
    "X_validate_numerical, scaler = features_scaling(df_validation, numerical_features)\n",
    "df_validate_numerical, scaler = features_scaling(df_validation, numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/scaler.joblib']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the scaler object in the models directory and naming the file as 'scaler.joblib'\n",
    "dump(scaler, '../../models/scaler.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Transforming categorical features data into numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking the function to transform the categorical 'item_id' feature values to numerical of the training and validation dataset\n",
    "item_id_train, ordinal = ordinal_transform(df_train, categorical_feature='item_id')\n",
    "item_id_validate, ordinal = ordinal_transform(df_validation, categorical_feature='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking the function to transform the categorical 'store_id' feature values to numerical of the training and validation dataset\n",
    "store_id_train, ordinal = ordinal_transform(df_train, categorical_feature='store_id')\n",
    "store_id_validate, ordinal = ordinal_transform(df_validation, categorical_feature='store_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking the function to transform the categorical 'event_name' feature values to numerical of the training and validation dataset\n",
    "event_name_train, ordinal = ordinal_transform(df_train, categorical_feature='event_name')\n",
    "event_name_validate, ordinal = ordinal_transform(df_validation, categorical_feature='event_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking the function to transform the categorical 'event_type' feature values to numerical of the training and validation dataset\n",
    "event_type_train, ordinal = ordinal_transform(df_train, categorical_feature='event_type')\n",
    "event_type_validate, ordinal = ordinal_transform(df_validation, categorical_feature='event_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/ordinal.joblib']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the ordinal object in the models directory and naming the file as 'ordinal.joblib'\n",
    "dump(ordinal, '../../models/ordinal.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Aggregating all the transformed predictors to form the features for both the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the transformed features of the training datatset\n",
    "X_train = X_train_numerical.copy()\n",
    "X_train['item_id'] = item_id_train['item_id']\n",
    "X_train['store_id'] = store_id_train['store_id']\n",
    "X_train['event_name'] = event_name_train['event_name']\n",
    "X_train['event_type'] = event_type_train['event_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the transformed features of the validation datatset\n",
    "X_validate = X_validate_numerical.copy()\n",
    "X_validate['item_id'] = item_id_validate['item_id']\n",
    "X_validate['store_id'] = store_id_validate['store_id']\n",
    "X_validate['event_name'] = event_name_validate['event_name']\n",
    "X_validate['event_type'] = event_type_validate['event_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Extracting response 'revenue' variable of training the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting values for target 'revenue' variable of training the validation dataset\n",
    "y_train = df_train['revenue']\n",
    "y_validate = df_validation['revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Storing the training and validation datasets in the data/processed directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking the function to store the prepared datasets in the data/processed directory\n",
    "save_datasets(X_train, y_train, X_validate, y_validate, path='../../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Modeling\n",
    "\n",
    "#### 7] Assessing Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a instance of the NullAccuracy class \n",
    "baseline = NullAccuracy()\n",
    "\n",
    "# Invoking a method to evaluate the baseline performance score\n",
    "y_base = baseline.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Scores:\n",
      "Baseline MAS score: 4.3372\n",
      "Baseline RMSE score: 9.0484\n"
     ]
    }
   ],
   "source": [
    "# Calculating the baseline performance scores MAS and RMSE   \n",
    "print('Performance Scores:') \n",
    "print('Baseline MAS score:', evaluating_mas_score(y_train, pd.Series(y_base.flatten())))\n",
    "print('Baseline RMSE score:', evaluating_rmse_score(y_train, pd.Series(y_base.flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8] Developing a Predictive Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Instantiating instance of the XGBoost Regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a 'xgb_regressor' instance using the XGBRegressor class with the default hyperparameters\n",
    "xgb_regressor = XGBRegressor(random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Fitting the XGBoost Regression model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=9, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=9, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=9, ...)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the XGBoost Regressor model using the selected features of the training dataset\n",
    "xgb_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Accessing the model performance measures on training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Scores of the XGBoost Algorithm:\n",
      "Training MAS score: 4.0605\n",
      "Training RMSE score: 8.7152\n"
     ]
    }
   ],
   "source": [
    "# Calculating the predicitive model's performance MAS and RMSE scores - training dataset\n",
    "print('Performance Scores of the XGBoost Algorithm:') \n",
    "print('Training MAS score:', evaluating_mas_score(y_train, xgb_regressor.predict(X_train)))\n",
    "print('Training RMSE score:', evaluating_rmse_score(y_train, xgb_regressor.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Scores of the XGBoost Algorithm:\n",
      "Validation MAS score: 4.3389\n",
      "Validation RMSE score: 10.4643\n"
     ]
    }
   ],
   "source": [
    "# Calculating the predicitive model's performance MAS and RMSE scores - validation dataset\n",
    "print('Performance Scores of the XGBoost Algorithm:') \n",
    "print('Validation MAS score:', evaluating_mas_score(y_validate, xgb_regressor.predict(X_validate)))\n",
    "print('Validation RMSE score:', evaluating_rmse_score(y_validate, xgb_regressor.predict(X_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Instantiating instance of the Linear Regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a 'lnr_regression' instance using the LinearRegression class with the default hyperparameters\n",
    "lnr_regression = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Fitting the Linear Regression model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Linear Regression model using the selected features of the training dataset\n",
    "lnr_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Accessing the model performance measures on training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Scores of the Linear Regression Algorithm:\n",
      "Training MAS score: 4.2788\n",
      "Training RMSE score: 9.0114\n"
     ]
    }
   ],
   "source": [
    "# Calculating the predicitive model's performance MAS and RMSE scores - training dataset\n",
    "print('Performance Scores of the Linear Regression Algorithm:') \n",
    "print('Training MAS score:', evaluating_mas_score(y_train, lnr_regression.predict(X_train)))\n",
    "print('Training RMSE score:', evaluating_rmse_score(y_train, lnr_regression.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Scores of the Linear Regression Algorithm:\n",
      "Validation MAS score: 4.4691\n",
      "Validation RMSE score: 10.6893\n"
     ]
    }
   ],
   "source": [
    "# Calculating the predicitive model's performance MAS and RMSE scores - validation dataset\n",
    "print('Performance Scores of the Linear Regression Algorithm:') \n",
    "print('Validation MAS score:', evaluating_mas_score(y_validate, lnr_regression.predict(X_validate)))\n",
    "print('Validation RMSE score:', evaluating_rmse_score(y_validate, lnr_regression.predict(X_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Developing a Pipeline to be employed as a ML Model Servicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Constructing a list to hold the features categorized as both numerical and categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to contain the list of features that are categorical and numerical datatype\n",
    "categorical_features = ['item_id', 'store_id', 'event_name', 'event_type']\n",
    "numerical_features = df_train.select_dtypes(include=['int64']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Establishing a pipeline called numerical_transformer for conducting scaling for numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a Pipeline named 'numerical_transformer' to conduct Scaling\n",
    "numerical_transformer = Pipeline(steps=[('scaling', StandardScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Establishing a Pipeline named categorical_transformer utilizing OneHotEncoder for categorical features transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a Pipeline named 'categorical_transformer' involving LabelEncoder to transform categorical features\n",
    "categorical_transformer = Pipeline(steps=[('ordinal_encoder', OrdinalEncoder())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Building a ColumnTransformer to preprocess numerical and categorical features separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a ColumnTransformer named 'preprocessor' to apply different preprocessing steps on the numerical and categorical features\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical_features', numerical_transformer, numerical_features), \n",
    "                                               ('categorical_features', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Forming a pipeline with two stages: preprocessing and the instantiation of an XGBoost Regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a pipeline comprising two stages: preprocessing and the instantiation of an XGBoost Regression algorithm instance\n",
    "xgb_pipe = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                           ('xgb_regressor', XGBRegressor(random_state=9))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Fitting the XGBoost Regression Predictive model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_features&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaling&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index([&#x27;day_of_week&#x27;, &#x27;month&#x27;, &#x27;year&#x27;, &#x27;week_of_year&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;categorical_features&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;ordinal_encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;item_id&#x27;, &#x27;store_id&#x27;,\n",
       "                                                   &#x27;event_name&#x27;,\n",
       "                                                   &#x27;event_type&#x27;])])),\n",
       "                (&#x27;xgb_regressor&#x27;...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=None, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=9, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_features&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaling&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index([&#x27;day_of_week&#x27;, &#x27;month&#x27;, &#x27;year&#x27;, &#x27;week_of_year&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;categorical_features&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;ordinal_encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;item_id&#x27;, &#x27;store_id&#x27;,\n",
       "                                                   &#x27;event_name&#x27;,\n",
       "                                                   &#x27;event_type&#x27;])])),\n",
       "                (&#x27;xgb_regressor&#x27;...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=None, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=9, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_features&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaling&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 Index([&#x27;day_of_week&#x27;, &#x27;month&#x27;, &#x27;year&#x27;, &#x27;week_of_year&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;categorical_features&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;ordinal_encoder&#x27;,\n",
       "                                                  OrdinalEncoder())]),\n",
       "                                 [&#x27;item_id&#x27;, &#x27;store_id&#x27;, &#x27;event_name&#x27;,\n",
       "                                  &#x27;event_type&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_features</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;day_of_week&#x27;, &#x27;month&#x27;, &#x27;year&#x27;, &#x27;week_of_year&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_features</label><div class=\"sk-toggleable__content\"><pre>[&#x27;item_id&#x27;, &#x27;store_id&#x27;, &#x27;event_name&#x27;, &#x27;event_type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=9, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('numerical_features',\n",
       "                                                  Pipeline(steps=[('scaling',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['day_of_week', 'month', 'year', 'week_of_year'], dtype='object')),\n",
       "                                                 ('categorical_features',\n",
       "                                                  Pipeline(steps=[('ordinal_encoder',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  ['item_id', 'store_id',\n",
       "                                                   'event_name',\n",
       "                                                   'event_type'])])),\n",
       "                ('xgb_regressor'...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=None, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=9, ...))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the XGBoost Regressor model using the selected features of the training dataset\n",
    "xgb_pipe.fit(df_train_copied, df_train_copied['revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Predicting revenue utilizing the trained pipeline for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.3664663, 3.3664663, 3.3664663, ..., 2.800957 , 2.800957 ,\n",
       "       2.800957 ], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizing the trained pipeline to predict revenue for the training dataset\n",
    "xgb_pipe.predict(df_train_copied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Utilizing the trained pipeline to make a revenue prediction for an individual data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.3664663], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizing the trained pipeline to predict revenue for the single datapoint\n",
    "obs = pd.DataFrame(df_train_copied.iloc[0]).transpose()\n",
    "xgb_pipe.predict(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Model Evaluation\n",
    "\n",
    "#### 10] Analysing Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Assessing the performance measures of the pipeline model employing the XGBoost Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Scores of the trained Pipeline employing XGBoost Algorithm:\n",
      "Training MAS score: 4.0605\n",
      "Training RMSE score: 8.7152\n"
     ]
    }
   ],
   "source": [
    "# Calculating pipeline's performance scores MAS and RMSE - training dataset\n",
    "print('Performance Scores of the trained Pipeline employing XGBoost Algorithm:') \n",
    "print('Training MAS score:', evaluating_mas_score(df_train_copied['revenue'], xgb_pipe.predict(df_train_copied)))\n",
    "print('Training RMSE score:', evaluating_rmse_score(df_train_copied['revenue'], xgb_pipe.predict(df_train_copied)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Scores of the trained Pipeline employing XGBoost Algorithm:\n",
      "Validation MAS score: 4.4432\n",
      "Validation RMSE score: 10.3767\n"
     ]
    }
   ],
   "source": [
    "# Calculating pipeline's performance scores MAS and RMSE - validation dataset\n",
    "print('Performance Scores of the trained Pipeline employing XGBoost Algorithm:') \n",
    "print('Validation MAS score:', evaluating_mas_score(df_validation_copied['revenue'], xgb_pipe.predict(df_validation_copied)))\n",
    "print('Validation RMSE score:', evaluating_rmse_score(df_validation_copied['revenue'], xgb_pipe.predict(df_validation_copied)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Saving the trained pipeline XGBoost model into the models directoy named as a 'xgbrevenue_predictiveregressor.joblib'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/predictive/xgbrevenue_predictiveregressor.joblib']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the fittted revenue forecasting phophet regressor in the models directory and naming the file as 'forecasting_revenue_regressor.joblib'\n",
    "dump(xgb_pipe, '../../models/predictive/xgbrevenue_predictiveregressor.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
